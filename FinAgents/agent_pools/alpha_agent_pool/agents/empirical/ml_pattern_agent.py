"""
ML Pattern Agent for Advanced Pattern Recognition in Financial Markets

This agent uses sophisticated machine learning techniques for pattern recognition
and prediction in financial time series data. It combines deep learning, ensemble
methods, and statistical analysis to identify complex market patterns.

Academic Framework:
Based on modern machine learning approaches in quantitative finance, including
deep learning for time series, ensemble methods, and advanced pattern recognition.

Author: FinAgent Research Team
Created: 2025-07-25
"""

import logging
import numpy as np
import pandas as pd
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass
import warnings

# Configure logging
logger = logging.getLogger(__name__)

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)

@dataclass
class MLPatternSignal:
    """Data structure for ML pattern-based trading signals."""
    symbol: str
    signal_strength: float
    pattern_name: str
    confidence: float
    model_type: str
    features_importance: Dict[str, float]
    timestamp: datetime
    expected_return: Optional[float] = None
    risk_estimate: Optional[float] = None
    pattern_duration: Optional[int] = None

@dataclass
class PatternTemplate:
    """Template for recognized market patterns."""
    pattern_id: str
    pattern_name: str
    sequence_length: int
    success_rate: float
    avg_return: float
    occurrence_frequency: float
    risk_metrics: Dict[str, float]

class MLPatternAgent:
    """
    ML Pattern Agent for advanced pattern recognition using machine learning.
    
    This agent employs sophisticated ML techniques including:
    - Time series pattern recognition
    - Ensemble learning methods  
    - Feature importance analysis
    - Pattern template matching
    - Predictive pattern modeling
    """
    
    def __init__(self, coordinator=None, config: Optional[Dict[str, Any]] = None):
        """
        Initialize ML Pattern Agent with configuration parameters.
        
        Args:
            coordinator: Agent coordinator for cross-agent communication
            config: Configuration dictionary containing:
                - sequence_length: Pattern sequence length (default: 30)
                - confidence_threshold: Minimum confidence for signals (default: 0.7)
                - n_estimators: Number of ensemble estimators (default: 100)
                - pattern_templates: Pre-defined pattern templates
        """
        self.coordinator = coordinator
        self.config = config or {}
        self.sequence_length = self.config.get('sequence_length', 30)
        self.confidence_threshold = self.config.get('confidence_threshold', 0.7)
        self.n_estimators = self.config.get('n_estimators', 100)
        
        # Pattern storage
        self.pattern_templates: List[PatternTemplate] = []
        self.feature_importance: Dict[str, float] = {}
        
        # Try to import ML libraries with fallback
        self.ml_available = self._initialize_ml_components()
        
        logger.info(f"MLPatternAgent initialized with sequence_length={self.sequence_length}, "
                   f"ML_available={self.ml_available}")
    
    async def initialize(self):
        """Initialize the agent asynchronously."""
        logger.info("ðŸ”§ Initializing ML Pattern Agent")
        # Add any async initialization logic here
        logger.info("âœ… ML Pattern Agent initialization completed")
    
    async def get_health_status(self) -> str:
        """Get agent health status."""
        return "healthy"
    
    async def shutdown(self):
        """Shutdown the agent."""
        logger.info("ðŸ›‘ Shutting down ML Pattern Agent")
    
    async def discover_ml_patterns(self, symbols: List[str], pattern_complexity: str = "moderate") -> Dict[str, Any]:
        """Discover ML patterns in the data."""
        logger.info(f"ðŸ¤– Discovering ML patterns for {len(symbols)} symbols")
        
        # Mock implementation for testing
        factors_discovered = []
        for i, symbol in enumerate(symbols):
            factors_discovered.append({
                "symbol": symbol,
                "factor_name": f"ml_pattern_{symbol.lower()}",
                "category": "technical",
                "pattern_type": "neural_network",
                "strength": 0.70 + (i * 0.05),
                "confidence": 0.88 - (i * 0.03)
            })
            
        return {
            "agent_id": "ml_pattern_agent",
            "factors_discovered": factors_discovered,
            "performance": {
                "patterns_found": len(factors_discovered),
                "execution_duration": 0.8,
                "success_rate": 0.87
            }
        }
    
    def _initialize_ml_components(self) -> bool:
        """Initialize ML components with fallback for missing dependencies."""
        try:
            # Try importing scikit-learn components
            from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
            from sklearn.preprocessing import StandardScaler, MinMaxScaler
            from sklearn.cluster import DBSCAN
            from sklearn.metrics import mean_squared_error
            from sklearn.model_selection import cross_val_score
            
            # Initialize ML models
            self.pattern_classifier = RandomForestRegressor(
                n_estimators=self.n_estimators, 
                random_state=42,
                max_depth=10
            )
            self.ensemble_model = GradientBoostingRegressor(
                n_estimators=50,
                random_state=42,
                max_depth=6
            )
            self.scaler = StandardScaler()
            self.pattern_clusterer = DBSCAN(eps=0.5, min_samples=5)
            
            return True
            
        except ImportError as e:
            logger.warning(f"ML libraries not available: {e}. Using statistical fallback.")
            return False
    
    def extract_pattern_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        Extract comprehensive pattern features from financial data.
        
        Args:
            data: Financial data with OHLCV columns
            
        Returns:
            DataFrame with extracted pattern features
        """
        try:
            features = pd.DataFrame(index=data.index)
            
            # Price features
            features['returns'] = data['close'].pct_change()
            features['log_returns'] = np.log(data['close'] / data['close'].shift(1))
            features['high_low_ratio'] = (data['high'] - data['low']) / data['close']
            features['open_close_ratio'] = (data['close'] - data['open']) / data['open']
            
            # Momentum features
            for window in [5, 10, 20]:
                features[f'momentum_{window}'] = data['close'] / data['close'].shift(window) - 1
                features[f'volatility_{window}'] = features['returns'].rolling(window).std()
                features[f'sharpe_{window}'] = (features['returns'].rolling(window).mean() / 
                                               features['returns'].rolling(window).std())
            
            # Pattern-specific features
            features['price_acceleration'] = features['returns'].diff()
            features['volume_price_trend'] = (features['returns'] * 
                                            np.log(data['volume']) if 'volume' in data.columns else 0)
            
            # Technical patterns
            features['doji_pattern'] = self._detect_doji_pattern(data)
            features['hammer_pattern'] = self._detect_hammer_pattern(data)
            features['engulfing_pattern'] = self._detect_engulfing_pattern(data)
            
            # Statistical features
            features['skewness'] = features['returns'].rolling(20).skew()
            features['kurtosis'] = features['returns'].rolling(20).kurt()
            features['autocorr'] = features['returns'].rolling(20).apply(
                lambda x: x.autocorr(lag=1) if len(x) > 1 else 0, raw=False
            )
            
            # Regime detection features
            features['regime_volatility'] = self._detect_volatility_regime(features['returns'])
            features['trend_strength'] = self._calculate_trend_strength(data['close'])
            
            return features.dropna()
            
        except Exception as e:
            logger.error(f"Error extracting pattern features: {e}")
            return pd.DataFrame()
    
    def _detect_doji_pattern(self, data: pd.DataFrame) -> pd.Series:
        """Detect Doji candlestick patterns."""
        body_size = abs(data['close'] - data['open']) / data['open']
        return (body_size < 0.01).astype(float)
    
    def _detect_hammer_pattern(self, data: pd.DataFrame) -> pd.Series:
        """Detect Hammer candlestick patterns."""
        body_size = abs(data['close'] - data['open'])
        lower_shadow = data['open'].combine(data['close'], min) - data['low']
        upper_shadow = data['high'] - data['open'].combine(data['close'], max)
        
        hammer_condition = (
            (lower_shadow > 2 * body_size) & 
            (upper_shadow < 0.1 * body_size) &
            (body_size > 0)
        )
        return hammer_condition.astype(float)
    
    def _detect_engulfing_pattern(self, data: pd.DataFrame) -> pd.Series:
        """Detect Engulfing candlestick patterns."""
        prev_body = abs(data['close'].shift(1) - data['open'].shift(1))
        curr_body = abs(data['close'] - data['open'])
        
        prev_green = data['close'].shift(1) > data['open'].shift(1)
        curr_red = data['close'] < data['open']
        
        engulfing = (
            (curr_body > prev_body * 1.1) &
            (prev_green & curr_red)
        )
        return engulfing.astype(float)
    
    def _detect_volatility_regime(self, returns: pd.Series, window: int = 20) -> pd.Series:
        """Detect volatility regime (0: low, 1: high)."""
        vol = returns.rolling(window).std()
        vol_threshold = vol.quantile(0.7)
        return (vol > vol_threshold).astype(float)
    
    def _calculate_trend_strength(self, prices: pd.Series, window: int = 20) -> pd.Series:
        """Calculate trend strength using linear regression slope."""
        def trend_slope(x):
            if len(x) < 2:
                return 0
            return np.polyfit(range(len(x)), x, 1)[0] / x.mean() if x.mean() != 0 else 0
        
        return prices.rolling(window).apply(trend_slope, raw=False)
    
    def create_pattern_sequences(self, features: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """
        Create sequential patterns for ML training.
        
        Args:
            features: Feature DataFrame
            
        Returns:
            Tuple of (X, y) arrays for ML training
        """
        if len(features) < self.sequence_length + 1:
            return np.array([]), np.array([])
        
        try:
            feature_cols = features.select_dtypes(include=[np.number]).columns
            feature_matrix = features[feature_cols].fillna(0).values
            
            X, y = [], []
            for i in range(len(feature_matrix) - self.sequence_length):
                # Input sequence
                X.append(feature_matrix[i:i + self.sequence_length])
                # Target: next period return
                if 'returns' in features.columns:
                    y.append(features['returns'].iloc[i + self.sequence_length])
                else:
                    y.append(0)
            
            return np.array(X), np.array(y)
            
        except Exception as e:
            logger.error(f"Error creating pattern sequences: {e}")
            return np.array([]), np.array([])
    
    def train_pattern_models(self, features: pd.DataFrame) -> bool:
        """
        Train ML models on pattern data.
        
        Args:
            features: Feature DataFrame
            
        Returns:
            True if training successful, False otherwise
        """
        if not self.ml_available or len(features) < self.sequence_length + 20:
            return False
        
        try:
            # Create sequences
            X, y = self.create_pattern_sequences(features)
            if len(X) == 0:
                return False
            
            # Reshape for traditional ML (flatten sequences)
            X_flat = X.reshape(X.shape[0], -1)
            
            # Train models
            self.pattern_classifier.fit(X_flat, y)
            self.ensemble_model.fit(X_flat, y)
            
            # Calculate feature importance
            if hasattr(self.pattern_classifier, 'feature_importances_'):
                feature_names = [f'feature_{i}' for i in range(X_flat.shape[1])]
                self.feature_importance = dict(zip(
                    feature_names, 
                    self.pattern_classifier.feature_importances_
                ))
            
            logger.info("Pattern models trained successfully")
            return True
            
        except Exception as e:
            logger.error(f"Error training pattern models: {e}")
            return False
    
    def generate_ml_signals(self, data: pd.DataFrame, symbol: str) -> List[MLPatternSignal]:
        """
        Generate trading signals using ML pattern recognition.
        
        Args:
            data: Market data DataFrame
            symbol: Stock symbol
            
        Returns:
            List of MLPatternSignal objects
        """
        try:
            # Extract features
            features = self.extract_pattern_features(data)
            if len(features) < self.sequence_length:
                return []
            
            signals = []
            
            # Statistical pattern signals (always available)
            stat_signals = self._generate_statistical_signals(features, symbol)
            signals.extend(stat_signals)
            
            # ML-based signals (if available)
            if self.ml_available:
                # Train models if not already trained
                if not hasattr(self.pattern_classifier, 'n_features_in_'):
                    trained = self.train_pattern_models(features)
                    if not trained:
                        logger.warning("Failed to train ML models, using statistical signals only")
                        return signals
                
                ml_signals = self._generate_ml_signals(features, symbol)
                signals.extend(ml_signals)
            
            # Sort by confidence
            signals.sort(key=lambda x: x.confidence, reverse=True)
            
            logger.info(f"Generated {len(signals)} ML pattern signals for {symbol}")
            return signals
            
        except Exception as e:
            logger.error(f"Error generating ML signals for {symbol}: {e}")
            return []
    
    def _generate_statistical_signals(self, features: pd.DataFrame, symbol: str) -> List[MLPatternSignal]:
        """Generate signals using statistical pattern analysis."""
        signals = []
        
        if 'returns' not in features.columns:
            return signals
        
        try:
            latest = features.iloc[-1]
            
            # Pattern-based signals
            patterns = {
                'momentum_breakout': latest.get('momentum_20', 0) > 0.05,
                'volatility_spike': latest.get('volatility_20', 0) > features['volatility_20'].quantile(0.8),
                'mean_reversion': abs(latest.get('momentum_10', 0)) > 0.03,
                'trend_continuation': abs(latest.get('trend_strength', 0)) > 0.02
            }
            
            for pattern_name, condition in patterns.items():
                if condition:
                    # Calculate signal strength based on pattern intensity
                    if pattern_name == 'momentum_breakout':
                        strength = min(latest.get('momentum_20', 0) * 10, 3.0)
                    elif pattern_name == 'volatility_spike':
                        strength = min(latest.get('volatility_20', 0) * 50, 2.0)
                    elif pattern_name == 'mean_reversion':
                        strength = -np.sign(latest.get('momentum_10', 0)) * min(abs(latest.get('momentum_10', 0)) * 20, 2.5)
                    else:
                        strength = latest.get('trend_strength', 0) * 30
                    
                    confidence = min(abs(strength) / 2.0, 1.0)
                    if confidence >= 0.5:  # Lower threshold for statistical signals
                        signal = MLPatternSignal(
                            symbol=symbol,
                            signal_strength=strength,
                            pattern_name=pattern_name,
                            confidence=confidence,
                            model_type='statistical',
                            features_importance={'pattern_strength': confidence},
                            timestamp=datetime.now(),
                            expected_return=strength * 0.01,  # Convert to expected return
                            risk_estimate=latest.get('volatility_20', 0.02)
                        )
                        signals.append(signal)
            
            return signals
            
        except Exception as e:
            logger.error(f"Error generating statistical signals: {e}")
            return []
    
    def _generate_ml_signals(self, features: pd.DataFrame, symbol: str) -> List[MLPatternSignal]:
        """Generate signals using ML models."""
        signals = []
        
        try:
            # Create latest sequence
            X, _ = self.create_pattern_sequences(features)
            if len(X) == 0:
                return signals
            
            # Get latest pattern
            latest_pattern = X[-1].reshape(1, -1)
            
            # Predict using ensemble
            rf_pred = self.pattern_classifier.predict(latest_pattern)[0]
            gb_pred = self.ensemble_model.predict(latest_pattern)[0]
            
            # Ensemble prediction
            ensemble_pred = (rf_pred + gb_pred) / 2
            
            # Calculate confidence based on model agreement
            model_agreement = 1 - abs(rf_pred - gb_pred) / (abs(rf_pred) + abs(gb_pred) + 1e-8)
            confidence = min(model_agreement * abs(ensemble_pred) * 50, 1.0)
            
            if confidence >= self.confidence_threshold:
                signal = MLPatternSignal(
                    symbol=symbol,
                    signal_strength=ensemble_pred * 100,  # Scale for signal strength
                    pattern_name='ml_ensemble',
                    confidence=confidence,
                    model_type='ensemble_ml',
                    features_importance=self.feature_importance,
                    timestamp=datetime.now(),
                    expected_return=ensemble_pred,
                    risk_estimate=abs(ensemble_pred) * 0.5,  # Risk proportional to prediction
                    pattern_duration=self.sequence_length
                )
                signals.append(signal)
            
            return signals
            
        except Exception as e:
            logger.error(f"Error generating ML signals: {e}")
            return []
    
    def get_strategy_metadata(self) -> Dict[str, Any]:
        """Get metadata about the ML pattern strategy."""
        return {
            'strategy_type': 'ml_pattern_recognition',
            'sequence_length': self.sequence_length,
            'confidence_threshold': self.confidence_threshold,
            'ml_available': self.ml_available,
            'n_estimators': self.n_estimators,
            'pattern_templates': len(self.pattern_templates),
            'description': 'Advanced pattern recognition using machine learning and statistical analysis'
        }

# Factory function for compatibility
def create_ml_pattern_agent(config: Optional[Dict[str, Any]] = None) -> MLPatternAgent:
    """Create and return an MLPatternAgent instance."""
    return MLPatternAgent(config)

# For backward compatibility and testing
if __name__ == "__main__":
    # Simple test
    agent = MLPatternAgent()
    
    # Generate test data
    np.random.seed(42)
    dates = pd.date_range('2024-01-01', periods=100, freq='D')
    
    test_data = pd.DataFrame({
        'open': 100 + np.cumsum(np.random.randn(100) * 0.5),
        'high': 0,
        'low': 0,
        'close': 100 + np.cumsum(np.random.randn(100) * 0.5),
        'volume': np.random.randint(1000, 10000, 100)
    }, index=dates)
    
    test_data['high'] = test_data[['open', 'close']].max(axis=1) + np.random.rand(100) * 2
    test_data['low'] = test_data[['open', 'close']].min(axis=1) - np.random.rand(100) * 2
    
    # Test signal generation
    signals = agent.generate_ml_signals(test_data, 'TEST')
    print(f"Generated {len(signals)} test ML signals")
    for signal in signals[:3]:  # Show first 3
        print(f"Signal: {signal.pattern_name}, Strength: {signal.signal_strength:.3f}, "
              f"Confidence: {signal.confidence:.3f}, Model: {signal.model_type}")
